"""Performing grouping and taxonomic taxonomic_classification

*Grouping reads to OTU's
Use three methods to group reads into OTU's, using an assigned level of similarity
- de novo
- closed-reference
- open-reference

*Taxonomic classification
Use three methods to classify the taxonomic classes
- BLAST+
    - consensus-blast: Performs BLAST+ local alignment between query and
    reference_reads, then assigns consensus taxonomy to each query sequence
    from among maxaccepts hits, min_consensus of which share that taxonomic
    assignment. Note that maxaccepts selects the first N hits with >
    perc_identity similarity to query, not the top N matches.
- VSEARCH
    - consensus-vsearch: Performs VSEARCH global alignment between query and
    reference_reads, then assigns consensus taxonomy to each query sequence
    from among maxaccepts top hits, min_consensus of which share that taxonomic
    assignment. Unlike classify-consensus-blast, this method searches the entire
    reference database before choosing the top N hits, not the first N hits.
- sci-kit learn

https://docs.qiime2.org/2019.4/plugins/available/feature-classifier/
"""
import os
import re
import subprocess
import sys

# reference the config file
conf = os.environ.get("conf")
configfile: conf

out_dir = config['out_dir'].rstrip('/') + '/'
exec_dir = config['exec_dir'].rstrip('/') + '/'
REF_DB = config['reference_db']

table_dir = config['table_dir']
repseq_dir = config['repseq_dir']
filt_file = config['filtfile_dir']
ref_dir = config['ref_dir'].rstrip('/') + '/'

de_novo_id = config['de_novo_id']
closed_id = config['closed_id']
open_id = config['open_id']

##############################
#Reference FASTA
ref_fasta_db = ['gg_13_8_otus/rep_set/99_otus.fasta', 'SILVA_132_QIIME_release/rep_set/rep_set_16S_only/99/silva_132_99_16S.fna']

ref_fasta_Dict = {}
for i in ref_fasta_db:
    refNoExt = i.split('_')[0]
    ref_fasta_Dict[refNoExt] = (ref_dir + i)

def get_rawref_full_path(wildcards):
    """
    """
    (refFullPath) = ref_fasta_Dict[wildcards.ref_raw]
    return refFullPath

##############################
#Reference Taxonomy
ref_tax_db = ['gg_13_8_otus/taxonomy/99_otu_taxonomy.txt', 'SILVA_132_QIIME_release/taxonomy/16S_only/99/taxonomy_all_levels.txt']

ref_tax_Dict = {}
for i in ref_tax_db:
    refNoExt = i.split('_')[0]
    ref_tax_Dict[refNoExt] = (ref_dir + i)

def get_taxref_full_path(wildcards):
    """
    """
    (refFullPath) = ref_tax_Dict[wildcards.ref_tax]
    return refFullPath

##############################
#Groupings for OTU clustering of open and closed reference
READ_GRP=['cl','op']
REF_GRP=['gg','SILVA']

readDict = {}
for a in READ_GRP:
    for b in REF_GRP:
        seqFile = out_dir + "rep-seqs_" + a + "_" + b + "_0.99.qza"
        tabFile = out_dir + "table_" + a + "_" + b + "_0.99.qza"
        readDict[a + b] = ([seqFile],[tabFile])

def get_seq_full_path(wildcards):
    """
    """
    (seqFile,tabFile) = readDict[wildcards.seq]
    return seqFile

#def get_tab_full_path(wildcards): ##delete?
#    """
#    """
#    (seqFile,tabFile) = readDict[wildcards.tab]
#    return tabFile

##############################
#Trained references classifers
refDict = {}
for i in REF_DB:
    refNoExt = i.split('/')[8].split('-')[0]
    refDict[refNoExt] = (i)

def get_ref_full_path(wildcards):
    """
    """
    (refFullPath) = refDict[wildcards.ref_train]
    return refFullPath

##############################
#move the previously created sci-kit files (created in Q2 SM pipeline)
#cp /DCEG/Projects/Microbiome/Analysis/Project_NP0084_MB/projects/20200410_2019.1/taxonomic_classification/classify-sklearn_gg-13-8-99-nb-classifier.qza /DCEG/Projects/Microbiome/Analysis/Project_NP0084_MB/aim1/scikit_dada_gg.qza

#cp /DCEG/Projects/Microbiome/Analysis/Project_NP0084_MB/projects/20200410_2019.1/taxonomic_classification/classify-sklearn_silva-132-99-nb-classifier.qza /DCEG/Projects/Microbiome/Analysis/Project_NP0084_MB/aim1/output/scikit_dada_SILVA.qza

##############################
#dict of refdb_seq to refdb_tax to sample_seq
classDICT={}
READ_GRP = ['cl_gg','cl_SILVA','dn','op_gg','op_SILVA']
REF_GRP = ['gg','silva']
ref_seq_art = ['refdb_seq_gg.qza','refdb_seq_SILVA.qza']
ref_tax_art = ['refdb_tax_gg.qza','refdb_tax_SILVA.qza']
count=0
for i in READ_GRP:
  for ref in REF_GRP:
    classDICT[i+"_"+ref] = [[out_dir + "rep-seqs_" + i + "_0.99.qza"],[out_dir + ref_seq_art[count]],[out_dir + ref_tax_art[count]]]
    count=count+1
  count=0

def get_consensuspaired_sampseq(wildcards):
  """
  """
  (sampseq,refseq,reftaxart)=classDICT[wildcards.consensus]
  return sampseq
def get_consensuspaired_refseq(wildcards):
    """
    """
    (sampseq,refseq,reftaxart)=classDICT[wildcards.consensus]
    return refseq
def get_consensuspaired_reftax(wildcards):
      """
      """
      (sampseq,refseq,reftaxart)=classDICT[wildcards.consensus]
      return reftaxart

rule all:
    input:
        out_dir + "filt_tab.qza",out_dir + "filt_seq.qza",
        expand(out_dir + 'refdb_seq_{ref_raw}.qza',ref_raw=ref_fasta_Dict.keys()),expand(out_dir + 'refdb_tax_{ref_raw}.qza',ref_raw=ref_tax_Dict.keys()),
        expand(out_dir + 'table_dn_{de_novo_id}.qza', de_novo_id=de_novo_id),expand(out_dir + 'rep-seqs_dn_{de_novo_id}.qza', de_novo_id=de_novo_id),
        expand(out_dir + 'table_cl_{ref_raw}_{closed_id}.qza', closed_id=closed_id, ref_raw=ref_fasta_Dict.keys()),expand(out_dir + 'rep-seqs_cl_{ref_raw}_{closed_id}.qza', closed_id=closed_id, ref_raw=ref_fasta_Dict.keys()),expand(out_dir + 'unmatched_cl_{ref_raw}_{closed_id}.qza', closed_id=closed_id, ref_raw=ref_fasta_Dict.keys()),
        expand(out_dir + 'table_op_{ref_raw}_{open_id}.qza', open_id=open_id, ref_raw=ref_fasta_Dict.keys()),expand(out_dir + 'rep-seqs_op_{ref_raw}_{open_id}.qza', open_id=open_id, ref_raw=ref_fasta_Dict.keys()),expand(out_dir + 'new_op_{ref_raw}_{open_id}.qza', open_id=open_id, ref_raw=ref_fasta_Dict.keys()),
        expand(out_dir + 'scikit_dn_{ref_train}.qza', ref_train=refDict.keys()), expand(out_dir + 'scikit_{seq}_{ref_train}.qza', seq=readDict.keys(), ref_train=refDict.keys()),
        expand(out_dir + 'blast' + '_{consensus}.qza',consensus=classDICT.keys()),
        expand(out_dir + 'vsearch' + '_{consensus}.qza',consensus=classDICT.keys())

rule feature_filt:
    """Filter features that have less than 32 reads
    VSEARCH will automatically remove features with <32 reads, however, QIIME2 does not do this. When the results are returned to Q2 without these reads, a KEYERROR is received.

    In order to determine which features, use the TABLE QZV and determine which features meet this requirement. Then create a TSV file with these features to pass through as a parameter of exclusion.

    NOTE: Removing features by count (<2 for example) would eliminate too many features that do not meet this criterion and may not even eliminate all of the targeted features.
    """
    input:
        tab_in = table_dir,
        f_list = filt_file
    output:
        tab_filt = out_dir + "filt_tab.qza"
    run:
        shell('qiime feature-table filter-features \
        --i-table {input.tab_in} \
        --m-metadata-file {input.f_list} \
        --p-exclude-ids \
        --o-filtered-table {output.tab_filt}')

rule seq_filt:
    """
    Rep-seqs must match features with the feature-table. Since features were filtered with rule above, this rule will remove those features from the rep-seq list.
    """
    input:
        tab_filt = out_dir + "filt_tab.qza",
        rep_in = repseq_dir
    output:
        rep_filt = out_dir + "filt_seq.qza"
    run:
        shell('qiime feature-table filter-seqs \
        --i-data {input.rep_in} \
        --i-table {input.tab_filt} \
        --o-filtered-data {output.rep_filt}')

rule create_ref_seq:
    """ Create the reference database to be used for taxonomic_classification
    used unaligned reads for this - creates ''FeatureData[Sequence]''
    """
    input:
        ref_raw = get_rawref_full_path
    output:
        out_dir + 'refdb_seq_{ref_raw}.qza'
    run:
        shell('qiime tools import \
        --type ''FeatureData[Sequence]'' \
        --input-path {input.ref_raw} \
        --output-path {output}')

rule create_ref_tax:
    """ Create the reference database to be used for taxonomic_classification
    used unaligned reads for this - creates ''FeatureData[Taxonomy]''
    """
    input:
        ref_tax = get_taxref_full_path
    output:
        out_dir + 'refdb_tax_{ref_tax}.qza'
    run:
        shell('qiime tools import \
        --type ''FeatureData[Taxonomy]'' \
        --input-path {input.ref_tax} \
        --input-format HeaderlessTSVTaxonomyFormat \
        --output-path {output}')

rule vsearch_de_novo:
    input:
        tab_f = out_dir + "filt_tab.qza",
        rep_f = out_dir + "filt_seq.qza"
    params:
        dn_id = de_novo_id
    output:
        out_tab = out_dir + 'table_dn_{de_novo_id}.qza',
        out_rep = out_dir + 'rep-seqs_dn_{de_novo_id}.qza'
    run:
        shell('qiime vsearch cluster-features-de-novo \
        --i-table {input.tab_f} \
        --i-sequences {input.rep_f} \
        --p-perc-identity {params.dn_id} \
        --o-clustered-table {output.out_tab} \
        --o-clustered-sequences {output.out_rep}')

rule vsearch_closed_ref:
    input:
        tab_f = out_dir + "filt_tab.qza",
        rep_f = out_dir + "filt_seq.qza",
        ref_fasta = out_dir + 'refdb_seq_{ref_raw}.qza'
    params:
        cl_id = closed_id
    output:
        out_tab = out_dir + 'table_cl_{ref_raw}_{closed_id}.qza',
        out_rep = out_dir + 'rep-seqs_cl_{ref_raw}_{closed_id}.qza',
        out_unmat = out_dir + 'unmatched_cl_{ref_raw}_{closed_id}.qza'
    run:
        shell('qiime vsearch cluster-features-closed-reference \
        --i-table {input.tab_f} \
        --i-sequences {input.rep_f} \
        --i-reference-sequences {input.ref_fasta} \
        --p-perc-identity {params.cl_id} \
        --o-clustered-table {output.out_tab} \
        --o-clustered-sequences {output.out_rep} \
        --o-unmatched-sequences {output.out_unmat}')

rule vsearch_open_ref:
    input:
        tab_f = out_dir + "filt_tab.qza",
        rep_f = out_dir + "filt_seq.qza",
        ref_fasta = out_dir + 'refdb_seq_{ref_raw}.qza'
    params:
        op_id = open_id
    output:
        out_tab = out_dir + 'table_op_{ref_raw}_{closed_id}.qza',
        out_rep = out_dir + 'rep-seqs_op_{ref_raw}_{closed_id}.qza',
        out_new = out_dir + 'new_op_{ref_raw}_{closed_id}.qza'
    run:
        shell('qiime vsearch cluster-features-open-reference \
        --i-table {input.tab_f} \
        --i-sequences {input.rep_f} \
        --i-reference-sequences {input.ref_fasta} \
        --p-perc-identity {params.op_id} \
        --o-clustered-table {output.out_tab} \
        --o-clustered-sequences {output.out_rep} \
        --o-new-reference-sequences {output.out_new}')

rule scikit_learn_dn:
    input:
        dn1 = out_dir + 'rep-seqs_dn_0.99.qza',
        ref_train = get_ref_full_path
    output:
        out_dir + 'scikit_dn_{ref_train}.qza'
    run:
        shell('qiime feature-classifier classify-sklearn \
            --i-classifier {input.ref_train} \
            --i-reads {input.dn1} \
            --o-classification {output}')

rule scikit_learn:
    input:
        seq = get_seq_full_path,
        ref_train = get_ref_full_path
    output:
        out_dir + 'scikit_{seq}_{ref_train}.qza'
    run:
        shell('qiime feature-classifier classify-sklearn \
            --i-classifier {input.ref_train} \
            --i-reads {input.seq} \
            --o-classification {output}')

rule blast:
    input:
        seq = get_consensuspaired_sampseq,
        ref_fasta = get_consensuspaired_refseq,
        ref_tax = get_consensuspaired_reftax
    output:
        out_dir + 'blast' + '_{consensus}.qza'
    run:
        shell('qiime feature-classifier classify-consensus-blast \
            --i-query {input.seq} \
            --i-reference-reads {input.ref_fasta} \
            --i-reference-taxonomy {input.ref_tax} \
            --o-classification {output}')

rule vsearch:
    input:
        seq = get_consensuspaired_sampseq,
        ref_fasta = get_consensuspaired_refseq,
        ref_tax = get_consensuspaired_reftax
    output:
        out_dir + 'vsearch' + '_{consensus}.qza'
    run:
        shell('qiime feature-classifier classify-consensus-vsearch \
            --i-query {input.seq} \
            --i-reference-reads {input.ref_fasta} \
            --i-reference-taxonomy {input.ref_tax} \
            --o-classification {output}')
