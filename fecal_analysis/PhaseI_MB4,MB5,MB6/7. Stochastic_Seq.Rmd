---
title: "7. StochasticCompare_Seq"
author: "Sevilla"
date: "October 12, 2019"
output: word_document
editor_options: 
  chunk_output_type: console
---
############### 
#Project Overview
To determine the stochastic affects that QIIME2 v1 pipeline has on OTU counts, subsequent taxonomic calling and precision/recall rates.

#QIIME2 Pipeline
Version 1 of the pipeline was used (T:\DCEG\Projects\Microbiome\CGR_MB\MicroBiome\sc_scripts_qiime2_pipeline\working) for this test. Three runs were performed using the sample dataset on three different start days. Each day was subsequently called "Stochastic_Run#". Output data is stored on the T Drive (T:\DCEG\Projects\Microbiome\CGR_MB\MicroBiome\Project_NP0084_MB4)

#Sample Set
Samples included in this anaysis were the sequencing controls of NP0084-MB4, MB5, and MB6, merged into one run. This includes a 43 controls samples of seven different mock communities and two blank-types.
-Project-ID: NP0084-MB4, NP0084-MB5, NP0084-MB6
-Sample-Cat: Seq.Blank, MSA, Zymo.Seq
-Sample-Descrip: NTC.Blank, PCR.Blank, MSA1000, MSA1001, MSA1002, MSA1003, D6305, D6306, D6311

#Analysis Overview
Phyloseq objects will be adapted from the analysis pipeline created for the fecal analysis of NP0084-MB4,MB5,MB6. This includes 1. Initial Processing which created the PhyloSeq objects from the three flowcells, and merged them together. OTU tables at two taxonomic levels (family and genus) were created during this step. and 2. Baseline_Seq which imported these taxonomic tables and merged the expected control information to created observed/expected data tables. Output data is stored on the T Drive (T:\DCEG\CGF\TechTransfer\Microbiome\Extraction\Optimization\Fecal\Fresh Fecal Optimization_2017.08\Phase I\Analysis\NP0084-MB4,5,6\R_Stochastic).

OTU tables will be compared below 

#Required libraries
```{r}
library("biom")
library(ape)
library(data.table)
library(ggplot2)
library(tm)
library(vegan)
library(tidyr)
library(cowplot)
library(scales)
library(phyloseq)
library(qiime2R)
library(tibble)
library(gridExtra)
source("sources/miseqR.R")
library(tidyverse)
source("sources/ggrare.R") #github library: https://rdrr.io/github/gauravsk/ranacapa/
library(compareDF)
```

#Input
```{r}
#Adapted from 1. Initital Processing code for fecal analysis
data_dir = c("T:\\DCEG\\Projects\\Microbiome\\CGR_MB\\MicroBiome\\")
project_name=c("Project_NP0084_MB4\\")
run_list=c("Stochastic_Run1","Stochastic_Run2","Stochastic_Run3")
manifest_name=c("NP0084-MB4_08_29_19_metadata_seq.txt")

output_location=c("T:\\DCEG\\CGF\\TechTransfer\\Microbiome\\Extraction\\Optimization\\Fecal\\Fresh Fecal Optimization_2017.08\\Phase I\\Analysis\\NP0084-MB4,5,6\\R_Stochastic\\")

sample_depth=100000
reference_db="greengenes"

#Adapted from 2. Baseline_Seq
control_location=c("T:\\DCEG\\CGF\\TechTransfer\\Microbiome\\Extraction\\Optimization\\Fecal\\Fresh Fecal Optimization_2017.08\\Phase I\\Controls\\Taxonomy\\")

#New Code Requirements
output_run_list=c("R_Run1","R_Run2","R_Run3")
taxa_levels=c("Family","Genus")
```

############### Adapted from 1. Initital Processing code for fecal analysis
#Directory Creation
```{r}
#Create directories - One for each output location, and the following subdirectories:
sub_create<-c("Data","Data\\Summary","Data\\Baseline","OTUs","Taxa","Graphs","Graphs\\Summary","Graphs\\Baseline")

for (a in output_run_list){
 dir.create(paste(output_location,a,sep=""))
 
 for (b in sub_create){
  dir.create(paste(output_location,a,"\\",b,sep=""))
 }
}

#Create one summary dir for misc. files
dir.create(paste(output_location,"Summary",sep=""))
```

#Create PhySeq Objects
```{r}
count=1
for (a in run_list){
 run_data_dir = paste(data_dir,project_name,a,sep="")

 #Read OTUS
 otus<-read_qza(paste(run_data_dir,"\\Output\\qza_results\\table_dada2_qza_merged_parts_final\\table_dada2_merged_final_filt.qza",sep=""))
 
 #Read rooted tree
 tree<-read_qza(paste(run_data_dir,"\\Output\\qza_results\\phylogeny_qza_results\\rooted_tree.qza",sep=""))
 
 #Read Greengenes taxonomy file
 taxonomy<-read_qza(paste(run_data_dir,"\\Output\\qza_results\\taxonomy_qza_results\\taxonomy_",reference_db,".qza",sep=""))
 
 #Edit table
 tax_table<-do.call(rbind, strsplit(as.character(taxonomy$data$Taxon), "; "))
   colnames(tax_table)<-c("Kingdom","Phylum","Class","Order","Family","Genus","Species")
   rownames(tax_table)<-taxonomy$data$Feature.ID
 
 #read metadata
 metadata<-read.table(paste(run_data_dir,manifest_name,sep="\\"),sep='\t', header=T, row.names=1, comment="")
 
 #Create phylo object
 phyloname<-paste("physeq_complete",count,sep="")
 assign(phyloname,phyloseq(otu_table(otus$data, taxa_are_rows = T), phy_tree(tree$data), tax_table(tax_table), sample_data(metadata)))
 
 phylo_number=count #sets the number of phyloseq objects that will need to be merged downstream
 count=count+1
}
```

#Handle Sample Data 
```{r}
#Remove quarantined samples
count=1
for (a in run_list){
 phy_name<-paste("physeq_complete",count,sep="")
 
 assign(phy_name,subset_samples(get(phy_name),Vial.ID!="Quarantined"))
 count=count+1
}


#Output
count=1
for (a in run_list){
 phy_name<-paste("physeq_complete",count,sep="")
 
 s<-summary(sample_data(get(phy_name)))
 capture.output(s, file = paste(output_location,output_run_list[count],"\\Data\\Summary\\summary_prefilter_",a,".txt",sep=""))
 o<-otu_table(get(phy_name))
 write.csv(o, file = paste(output_location,output_run_list[count],"\\OTUs\\otu_table_",a,".csv",sep=""))
 
 count=count+1
}

remove(s,o)

```

#Prune taxonmoy
```{r}
#Prune for bacteria only
count=1
for (a in run_list){
 phy_name<-paste("physeq_complete",count,sep="")
 phy_filt_name<-paste("physeq_filt",count,sep="")
  
 assign(phy_filt_name,get(phy_name) %>%
  subset_taxa(
    Kingdom == "k__Bacteria" &
    Family  != "k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rickettsiales; f__mitochondria" &
    Class   != "k__Bacteria; p__Cyanobacteria; c__Chloroplast"
  ))

 #Print summaries
 s<-summary(sample_data(get(phy_filt_name))$Sample.Cat)
 capture.output(s, file = paste(output_location,output_run_list[count],"\\Data\\Summary\\summary_prefilter_sample_",a,".Cat.txt",sep=""))
 s<-summary(sample_data(get(phy_filt_name))$Sample.Descrip)
 capture.output(s, file = paste(output_location,output_run_list[count],"\\Data\\Summary\\summary_prefilter_sample_",a,".Descrip.txt",sep=""))
 
 count=count+1
}

```

#Filter taxa >.001, filter samples with less than 10000 read
```{r}
#NOTE: Samples should have been filtered during Q2 pipeline - done to ensure this was completed
count=1
for (a in run_list){
 phy_filt_name<-paste("physeq_filt",count,sep="")
 
 assign(phy_filt_name, filter_taxa(get(phy_filt_name), function(x) mean(x) > 1e-2, TRUE))
 assign(phy_filt_name, prune_samples(sample_sums(get(phy_filt_name)) > 10000, get(phy_filt_name)))
 assign(phy_filt_name, get(phy_filt_name) %>% scale_reads(n=sample_depth))

 
 o<-otu_table(get(phy_name))
 write.csv(o, file = paste(output_location,output_run_list[count],"\\OTUs\\otu_table_filt_",a,".csv",sep=""))

 count=count+1
}

```

#Merge OTU's into taxa tables
```{r}
count=1
for (a in output_run_list){
 
 phy_filt_name<-paste("physeq_filt",count,sep="")

 for (b in taxa_levels){
  
  # Create a factor corresponding to the taxalevel
  taxfac = factor(tax_table(get(phy_filt_name))[, b])
  
  # Tabulate the counts for each genera in each sample
  taxtab = apply(otu_table(get(phy_filt_name)), MARGIN = 2, function(x) {
     tapply(x, INDEX = taxfac, FUN = sum, na.rm = TRUE, simplify = TRUE)
  })
  taxtab<-as.data.frame(taxtab)
 
  for (c in rownames(taxtab)){
   taxa<-c
   
   if(b=="Genus"){
    
    if(!grepl("g__",taxa)){
    taxtab[c,b]<-"HigherGenus"
    } else{
    colname_update<-str_remove(c, "g__") #Need to remove the formatting of taxonmy for each viewing downstream
    }
   } else{
    if(!grepl("f__",taxa)){
    taxtab[c,b]<-"HigherFamily"
    } else{
    colname_update<-str_remove(c, "f__") #Need to remove the formatting of taxonmy for each viewing downstream
    }
    
   }
   
   colname_update<-gsub("[","",colname_update,fixed=TRUE) #fixed = TRUE disables regex
   colname_update<-gsub("]","",colname_update,fixed=TRUE)
   taxtab[c,b]<-colname_update
   
  }
  
  taxtab<-aggregate(taxtab[-ncol(taxtab)],by=list(taxtab[,b]),FUN="sum") #use -ncol since first col should not be summed
  
  #Check if there is a blank first column because any unassigned taxa (originally was "g__") will be blank due to above
  if(taxtab[1,1]==""){
  taxtab[1,1]<-"Unknown"
  }
  
  taxtab<-t(taxtab) #transpose for downstream metadata matching
  colnames(taxtab)<-taxtab[1,]
  taxtab<-taxtab[-1,]
  
  file_name =paste(output_location,a,"\\Taxa\\taxa_Summary_",b,"_",run_list[count],".csv",sep="")
  write.csv(taxtab,file_name)
 
  metatab <- as.data.frame(sample_data(get(phy_filt_name)))
  file_name =paste(output_location,a,"\\Taxa\\metadata_Summary_",b,"_",run_list[count],".csv",sep="")
  write.csv(metatab,file_name)
 }
 count=count+1
}
```

################## New Code
#Read in raw OTU tables
```{r}
count=1
for (a in output_run_list){
 
 otu_table_name<-paste("otu_",a,sep="")
 assign(otu_table_name,read.csv(paste(output_location,a,"\\OTUs\\otu_table_filt_",run_list[count],".csv",sep="")))
 
 count=count+1
}

```

#Compare OTU tables
```{r}
#Determine if there are differences in the OTU read counts between the three stochastic runs 
#NOTE: This is after downsampling has occured
otu_diff_1to2 <- compare_df(otu_R_Run1,otu_R_Run2)
otu_diff_1to3 <- compare_df(otu_R_Run1,otu_R_Run3)
otu_diff_2to3 <- compare_df(otu_R_Run3,otu_R_Run3)

#Result: All of the tables are the same. No comparison needed at taxonomy levels.
```

################## Adapted from 2. Baseline_Seq
#NOTE: Will only use R_Run1 for the rest of the analysis, as all OTU information was the same, therefore taxonomic information will not vary

#Taxonomy Reference
```{r}
#Read in controls taxonomy file, grouped by taxa
count=1
for (a in taxa_levels){
 expected_name<-paste("expected_taxa_",a,sep="")

 assign(expected_name,read.table(paste(control_location,"Taxonomy_",a,"_2019.txt",sep=""),sep="\t",header=TRUE,row.names=count+6))
 
 assign(expected_name,get(expected_name)[-1])
 count=count+1
}
```

#Store in taxa tables
```{r}
for (a in taxa_levels){
 tax_table_name<-paste("taxa",a,sep="_")
 assign(tax_table_name,read.csv(paste(output_location,output_run_list[1],"\\Taxa\\taxa_Summary_",b,"_",run_list[1],".csv",sep=""),row.names=1))
}

taxa_Family$Total_OTUs<-rowSums(taxa_Family)
taxa_Genus$Total_OTUs<-rowSums(taxa_Genus)
```

#Observed to Expected Counts
```{r}
samplelist_seqcontrols<-rownames(otu_baseline_complete)
observed_baseline_seqcontrols<- data.frame()
taxa_observed=colnames(otu_baseline_complete)
taxa_observed=taxa_observed[-length(taxa_observed)]#Remove Total_OTUs

observed_count=0
notobserved_count=0

#Individual Samples
for (a in samplelist_seqcontrols){
 control_type <- as.String(metadata_baseline[a,"Source.Descrip"])
 taxa_temp <- control_expect[,c("Gram",control_type)]
 taxa_temp <- row.names(subset(taxa_temp,!(taxa_temp[,control_type]=="A")))
 
 for (b in taxa_temp){ #for all expected taxa, determine which are observed
  otu_count <- otu_baseline_complete[a,b]
  
  if(!(is.na(observed_count) || is.null(otu_count) || otu_count==0)){ #for all taxa with a positive OTU count
    observed_count= observed_count+1
  } else{
   notobserved_count=notobserved_count+1
  }
 }
 
 observed_baseline_seqcontrols[a,"Observed"] <- observed_count
 observed_baseline_seqcontrols[a,"Expected"] <- length(taxa_temp)
 observed_baseline_seqcontrols[a,"Observed_NotExpected"] <- sum(otu_baseline_complete[a,]>1)-1-observed_count #total-1 for total OTU column
 observed_baseline_seqcontrols[a,"Expected_NotObserved"] <- notobserved_count
 observed_baseline_seqcontrols[a,"Source.Descrip"] <- metadata_baseline[a,"Source.Descrip"]
 observed_count=0
 notobserved_count=0
}

#Average by Source.Descrip
observed_count=0
observednotexp_count=0
notobserved_count=0
count=0
source_list<-unique(observed_baseline_seqcontrols$Source.Descrip)

for (a in source_list){
 for (b in samplelist_seqcontrols){
  control_type <- as.String(metadata_baseline[b,"Source.Descrip"])
  if(a==control_type){
   observed_count<-observed_baseline_seqcontrols[b,"Observed"]+observed_count
   observednotexp_count<-observed_baseline_seqcontrols[b,"Observed_NotExpected"]+observednotexp_count
   notobserved_count<-observed_baseline_seqcontrols[b,"Expected_NotObserved"]+notobserved_count
   expected_count<-observed_baseline_seqcontrols[b,"Expected"]
   count=count+1
  }
 }
 observed_baseline_seqcontrols[a,"Observed"]<-observed_count/count
 observed_baseline_seqcontrols[a,"Expected"]<-expected_count
 observed_baseline_seqcontrols[a,"Observed_NotExpected"]<-observednotexp_count/count
 observed_baseline_seqcontrols[a,"Expected_NotObserved"]<-notobserved_count/count
 observed_baseline_seqcontrols[a,"Source.Descrip"]<-a
 
 observed_count=0
 observednotexp_count=0
 notobserved_count=0
 count=0
}

write.csv(observed_baseline_seqcontrols,paste(output_location,"Data\\Baseline\\observed_baseline_",taxa_level,"_seqcontrols.csv",sep=""))
```

#Relative Abundance  - Seq Controls
```{r}
relabun_baseline_seqcontrols<-data.frame()

#Complete Relative Abundance
samplelist_seqcontrols<-rownames(otu_baseline_complete)
taxa_list <- colnames(otu_baseline_complete)
taxa_list<-taxa_list[-(length(taxa_list))]
taxa_list<-append(taxa_list,rownames(control_expect))

for (a in samplelist_seqcontrols){
 for (b in taxa_list){
  
  relabun <- otu_baseline_complete[a,b]
  
  if(!(is.na(relabun) || is.null(relabun) || relabun==0)){
   relabun_baseline_seqcontrols[a,b] <- otu_baseline_complete[a,b]/otu_baseline_complete[a,"Total_OTUs"]
   relabun_baseline_seqcontrols[a,"Source.Descrip"]<-as.character(metadata_baseline[a,"Source.Descrip"])
  }
  control_type<-as.character(metadata_baseline[a,"Source.Descrip"])
  relabun_baseline_seqcontrols[control_type,b]<-as.character(control_expect[b,control_type])
  relabun_baseline_seqcontrols[control_type,"Source.Descrip"]<-control_type
 }
}

relabun_baseline_seqcontrols[is.na(relabun_baseline_seqcontrols)]=0 #replace na's with 0
relabun_baseline_seqcontrols[relabun_baseline_seqcontrols=="A"]=0 #replace A's with 0
write.csv(relabun_baseline_seqcontrols,paste(output_location,"Data\\Baseline\\relabun_baseline_seqcontrols.csv",sep=""))
```

#6 Plot graph - IntraControl Variability
For each kit, show variability, and map
```{r}
ordu = ordinate(physeq_filt_seqcontrols, "PCoA", "unifrac", weighted=TRUE)
plot_ordination(physeq_filt_seqcontrols, ordu, color="Source.Descrip")
```

####################




#Observed/Expected Tables
```{r}
for (a in output_run_list){
 
 for (b in taxa_levels){
  
  taxa_table_name<-paste("obs_",a,"_",b,sep="")
  
  assign(taxa_table_name,read.csv(paste(output_location,"\\Taxa\\",b,"\\",a,"_observed_baseline_seqcontrols.csv",sep=""),row.names=1))
 }
}

```

#Compare Taxa Tables
```{r}
#Not necessary, since the OTU tables were the same - merged at the taxa level will not show any difference
#obs_diff_1to2_Family <- compare_df(obs_R_Run1_Family,obs_R_Run2_Family)
```

#Determine TAR and TDR
```{r}
#Need to determine the TP, FP, FN rate for each of the runs. Then will calculate the TAR (taxon accuracty rate - TP/TP+FP) and the TDR (taxon detection rate - TP/TP+FN) at each taxa level

control_list<-c("MSA1000","MSA1001","MSA1002","MSA1003","D6305","D6306","D6311")
obs_merged<-data.frame()

for (a in output_run_list){
 for (b in taxa_level){
  table_name<-(paste("obs",a,b,sep="_"))
  tmp<-get(table_name)
  
  for(c in control_list){
   sample_name<-paste(c,a,b,sep="_")
   
   obs_merged[sample_name,"TP"]<-tmp[c,"Observed"]
   obs_merged[sample_name,"FP"]<-tmp[c,"Observed_NotExpected"]
   obs_merged[sample_name,"FN"]<-tmp[c,"Expected_NotObserved"]

   obs_merged[sample_name,"TAR"]<-tmp[c,"Observed"]/(tmp[c,"Observed"]+tmp[c,"Observed_NotExpected"])
   obs_merged[sample_name,"TDR"]<-tmp[c,"Observed"]/(tmp[c,"Observed"]+tmp[c,"Expected_NotObserved"])
  }
 }
}
  
write.csv(obs_merged,paste(output_location,"Summary\\obs_diffs.csv",sep=""))
```
