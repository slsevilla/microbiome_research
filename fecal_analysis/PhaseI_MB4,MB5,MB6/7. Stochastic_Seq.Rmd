---
title: "7. StochasticCompare_Seq"
author: "Sevilla"
date: "October 12, 2019"
output: word_document
editor_options: 
  chunk_output_type: console
---
############### 
#Project Overview
To determine the stochastic affects that QIIME2 v1 pipeline has on OTU counts, subsequent taxonomic calling and precision/recall rates.

#QIIME2 Pipeline
Version 1 of the pipeline was used (T:\DCEG\Projects\Microbiome\CGR_MB\MicroBiome\sc_scripts_qiime2_pipeline\working) for this test. Three runs were performed using the sample dataset on three different start days. Each day was subsequently called "Stochastic_Run#". Output data is stored on the T Drive (T:\DCEG\Projects\Microbiome\CGR_MB\MicroBiome\Project_NP0084_MB4)

#Sample Set
Samples included in this anaysis were the sequencing controls of NP0084-MB4, MB5, and MB6, merged into one run. This includes a 43 controls samples of seven different mock communities and two blank-types.
-Project-ID: NP0084-MB4, NP0084-MB5, NP0084-MB6
-Sample-Cat: Seq.Blank, MSA, Zymo.Seq
-Sample-Descrip: NTC.Blank, PCR.Blank, MSA1000, MSA1001, MSA1002, MSA1003, D6305, D6306, D6311

#Analysis Overview
Phyloseq objects will be adapted from the analysis pipeline created for the fecal analysis of NP0084-MB4,MB5,MB6. This includes 1. Initial Processing which created the PhyloSeq objects from the three flowcells, and merged them together. OTU tables at two taxonomic levels (family and genus) were created during this step. and 2. Baseline_Seq which imported these taxonomic tables and merged the expected control information to created observed/expected data tables. Output data is stored on the T Drive (T:\DCEG\CGF\TechTransfer\Microbiome\Extraction\Optimization\Fecal\Fresh Fecal Optimization_2017.08\Phase I\Analysis\NP0084-MB4,5,6\R_Stochastic).

OTU tables will be compared below 

#Required libraries
```{r}
library("biom")
library(ape)
library(data.table)
library(ggplot2)
library(tm)
library(vegan)
library("biom")
library(tidyr)
library(ggplot2)
library(cowplot)
library(scales)
library(phyloseq)
library(qiime2R)
library(tibble)
library(gridExtra)
source("sources/miseqR.R")
library(tidyverse)
source("sources/ggrare.R") #github library: https://rdrr.io/github/gauravsk/ranacapa/
library(ggplot2)
library(compareDF)
```

############### 
#Input
```{r}
#Adapted from 1. Initital Processing code for fecal analysis
data_dir = c("T:\\DCEG\\Projects\\Microbiome\\CGR_MB\\MicroBiome\\")
project_name=c("Project_NP0084_MB4\\")
run_list=c("Stochastic_Run1","Stochastic_Run2","Stochastic_Run3")
manifest_name=c("NP0084-MB4_08_29_19_metadata_seq.txt")

output_location=c("T:\\DCEG\\CGF\\TechTransfer\\Microbiome\\Extraction\\Optimization\\Fecal\\Fresh Fecal Optimization_2017.08\\Phase I\\Analysis\\NP0084-MB4,5,6\\R_Stochastic\\")

sample_depth=100000
reference_db="greengenes"

#New Code
output_run_list=c("R_Run1","R_Run2","R_Run3")

taxa_levels=c("Family","Genus")
```

#Adapted from 1. Initital Processing code for fecal analysis
############### 
#Directory Creation
```{r}
#Create directories - One for each output location, and the following subdirectories:
sub_create<-c("Data","Data\\Summary","Data\\Baseline","OTUs","Taxa","Graphs","Graphs\\Summary","Graphs\\Baseline")

for (a in output_run_list){
 dir.create(paste(output_location,a,sep=""))
 
 for (b in sub_create){
  dir.create(paste(output_location,a,"\\",b,sep=""))
 }
}

#Create one summary dir for misc. files
dir.create(paste(output_location,"Summary",sep=""))
```

#Create PhySeq Objects
```{r}
count=1
for (a in run_list){
 run_data_dir = paste(data_dir,project_name,a,sep="")

 #Read OTUS
 otus<-read_qza(paste(run_data_dir,"\\Output\\qza_results\\table_dada2_qza_merged_parts_final\\table_dada2_merged_final_filt.qza",sep=""))
 
 #Read rooted tree
 tree<-read_qza(paste(run_data_dir,"\\Output\\qza_results\\phylogeny_qza_results\\rooted_tree.qza",sep=""))
 
 #Read Greengenes taxonomy file
 taxonomy<-read_qza(paste(run_data_dir,"\\Output\\qza_results\\taxonomy_qza_results\\taxonomy_",reference_db,".qza",sep=""))
 
 #Edit table
 tax_table<-do.call(rbind, strsplit(as.character(taxonomy$data$Taxon), "; "))
   colnames(tax_table)<-c("Kingdom","Phylum","Class","Order","Family","Genus","Species")
   rownames(tax_table)<-taxonomy$data$Feature.ID
 
 #read metadata
 metadata<-read.table(paste(run_data_dir,manifest_name,sep="\\"),sep='\t', header=T, row.names=1, comment="")
 
 #Create phylo object
 phyloname<-paste("physeq_complete",count,sep="")
 assign(phyloname,phyloseq(otu_table(otus$data, taxa_are_rows = T), phy_tree(tree$data), tax_table(tax_table), sample_data(metadata)))
 
 phylo_number=count #sets the number of phyloseq objects that will need to be merged downstream
 count=count+1
}
```

#Handle Sample Data 
```{r}
#Remove quarantined samples
count=1
for (a in run_list){
 phy_name<-paste("physeq_complete",count,sep="")
 
 assign(phy_name,subset_samples(get(phy_name),Vial.ID!="Quarantined"))
 count=count+1
}


#Output
count=1
for (a in run_list){
 phy_name<-paste("physeq_complete",count,sep="")
 
 s<-summary(sample_data(get(phy_name)))
 capture.output(s, file = paste(output_location,output_run_list[count],"\\Data\\Summary\\summary_prefilter_",a,".txt",sep=""))
 o<-otu_table(get(phy_name))
 write.csv(o, file = paste(output_location,output_run_list[count],"\\OTUs\\otu_table_",a,".csv",sep=""))
 
 count=count+1
}

remove(s,o)

```

#Prune taxonmoy
```{r}
#Prune for bacteria only
count=1
for (a in run_list){
 phy_name<-paste("physeq_complete",count,sep="")
 phy_filt_name<-paste("physeq_filt",count,sep="")
  
 assign(phy_filt_name,get(phy_name) %>%
  subset_taxa(
    Kingdom == "k__Bacteria" &
    Family  != "k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rickettsiales; f__mitochondria" &
    Class   != "k__Bacteria; p__Cyanobacteria; c__Chloroplast"
  ))

 #Print summaries
 s<-summary(sample_data(get(phy_filt_name))$Sample.Cat)
 capture.output(s, file = paste(output_location,output_run_list[count],"\\Data\\Summary\\summary_prefilter_sample_",a,".Cat.txt",sep=""))
 s<-summary(sample_data(get(phy_filt_name))$Sample.Descrip)
 capture.output(s, file = paste(output_location,output_run_list[count],"\\Data\\Summary\\summary_prefilter_sample_",a,".Descrip.txt",sep=""))
 
 count=count+1
}

```

#Filter taxa >.001, filter samples with less than 10000 read
```{r}
#NOTE: Samples should have been filtered during Q2 pipeline - done to ensure this was completed
count=1
for (a in run_list){
 phy_filt_name<-paste("physeq_filt",count,sep="")
 
 assign(phy_filt_name, filter_taxa(get(phy_filt_name), function(x) mean(x) > 1e-2, TRUE))
 assign(phy_filt_name, prune_samples(sample_sums(get(phy_filt_name)) > 10000, get(phy_filt_name)))
 assign(phy_filt_name, get(phy_filt_name) %>% scale_reads(n=sample_depth))

 
 o<-otu_table(get(phy_name))
 write.csv(o, file = paste(output_location,output_run_list[count],"\\OTUs\\otu_table_filt_",a,".csv",sep=""))

 count=count+1
}

```

#Merge OTU's into taxa tables
```{r}
count=1
for (a in output_run_list){
 
 phy_filt_name<-paste("physeq_filt",count,sep="")

 for (b in taxa_levels){
  
  # Create a factor corresponding to the taxalevel
  taxfac = factor(tax_table(get(phy_filt_name))[, b])
  
  # Tabulate the counts for each genera in each sample
  taxtab = apply(otu_table(get(phy_filt_name)), MARGIN = 2, function(x) {
     tapply(x, INDEX = taxfac, FUN = sum, na.rm = TRUE, simplify = TRUE)
  })
  taxtab<-as.data.frame(taxtab)
 
  for (c in rownames(taxtab)){
   taxa<-c
   
   if(b=="Genus"){
    
    if(!grepl("g__",taxa)){
    taxtab[c,b]<-"HigherGenus"
    } else{
    colname_update<-str_remove(c, "g__") #Need to remove the formatting of taxonmy for each viewing downstream
    }
   } else{
    if(!grepl("f__",taxa)){
    taxtab[c,b]<-"HigherFamily"
    } else{
    colname_update<-str_remove(c, "f__") #Need to remove the formatting of taxonmy for each viewing downstream
    }
    
   }
   
   colname_update<-gsub("[","",colname_update,fixed=TRUE) #fixed = TRUE disables regex
   colname_update<-gsub("]","",colname_update,fixed=TRUE)
   taxtab[c,b]<-colname_update
   
  }
  
  taxtab<-aggregate(taxtab[-ncol(taxtab)],by=list(taxtab[,b]),FUN="sum") #use -ncol since first col should not be summed
  
  #Check if there is a blank first column because any unassigned taxa (originally was "g__") will be blank due to above
  if(taxtab[1,1]==""){
  taxtab[1,1]<-"Unknown"
  }
  
  taxtab<-t(taxtab) #transpose for downstream metadata matching
  colnames(taxtab)<-taxtab[1,]
  taxtab<-taxtab[-1,]
  
  file_name =paste(output_location,a,"\\Taxa\\taxa_Summary_",b,"_",run_list[count],".csv",sep="")
  write.csv(taxtab,file_name)
 
  metatab <- as.data.frame(sample_data(get(phy_filt_name)))
  file_name =paste(output_location,a,"\\Taxa\\metadata_Summary_",b,"_",run_list[count],".csv",sep="")
  write.csv(metatab,file_name)
 }
 count=count+1
}
```
##################
####################
#######################

#OTU tables
```{r}
for (a in output_run_list){
 
 #Copy otu tables in case future project data is archived
 file.copy(paste(output_location,a,"\\OTUs\\otu_table.csv",sep=""),paste(output_location,"Summary\\OTU\\",a,"_otu_table.csv",sep=""))
 
 otu_table_name<-paste("otu_",a,sep="")
 
 assign(otu_table_name,read.csv(paste(output_location,"Summary\\OTU\\",a,"_otu_table.csv",sep="")))
}

```

#Compare OTU tables
```{r}
#Determine if there are differences in the OTU read counts between the three stochastic runs 
#NOTE: This is after downsampling has occured
otu_diff_1to2 <- compare_df(otu_R_Run1,otu_R_Run2)
otu_diff_1to3 <- compare_df(otu_R_Run1,otu_R_Run3)
otu_diff_2to3 <- compare_df(otu_R_Run3,otu_R_Run3)

```

#Read in Observed/Expected Tables
```{r}
#Move taxa tables to summary document for easy access, read in the tables
for (a in output_run_list){
 
 for (b in taxa_level){
   file.copy(paste(output_location,a,"\\Data\\Baseline\\observed_baseline_",b,"_seqcontrols.csv",sep=""),paste(output_location,"Summary\\",b,"\\",a,"_observed_baseline_seqcontrols.csv",sep=""))
 
 obs_table_name<-paste("obs_",a,"_",b,sep="")
 
 assign(obs_table_name,read.csv(paste(output_location,"Summary\\",b,"\\",a,"_observed_baseline_seqcontrols.csv",sep=""),row.names=1))
 }
}

```

#Compare Taxa Tables
```{r}
#Not necessary, since the OTU tables were the same - merged at the taxa level will not show any difference
#obs_diff_1to2_Family <- compare_df(obs_R_Run1_Family,obs_R_Run2_Family)
```

#Determine TAR and TDR
```{r}
#Need to determine the TP, FP, FN rate for each of the runs. Then will calculate the TAR (taxon accuracty rate - TP/TP+FP) and the TDR (taxon detection rate - TP/TP+FN) at each taxa level

control_list<-c("MSA1000","MSA1001","MSA1002","MSA1003","D6305","D6306","D6311")
obs_merged<-data.frame()

for (a in output_run_list){
 for (b in taxa_level){
  table_name<-(paste("obs",a,b,sep="_"))
  tmp<-get(table_name)
  
  for(c in control_list){
   sample_name<-paste(c,a,b,sep="_")
   
   obs_merged[sample_name,"TP"]<-tmp[c,"Observed"]
   obs_merged[sample_name,"FP"]<-tmp[c,"Observed_NotExpected"]
   obs_merged[sample_name,"FN"]<-tmp[c,"Expected_NotObserved"]

   obs_merged[sample_name,"TAR"]<-tmp[c,"Observed"]/(tmp[c,"Observed"]+tmp[c,"Observed_NotExpected"])
   obs_merged[sample_name,"TDR"]<-tmp[c,"Observed"]/(tmp[c,"Observed"]+tmp[c,"Expected_NotObserved"])
  }
 }
}
  
write.csv(obs_merged,paste(output_location,"Summary\\obs_diffs.csv",sep=""))
```
